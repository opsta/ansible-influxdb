---
influxdb_service_name: influxdb

influxdb_search_config_path: "{{ playbook_dir }}/files/groups/{{ item }}/influxdb"
influxdb_search_config_paths: []
influxdb_host_config_file_path: "{{ influxdb_host_config_path | default(inventory_hostname) }}/influxdb.conf.j2"
influxdb_host_config_ssl_path:  "{{ influxdb_host_config_path | default(inventory_hostname) }}/ssl"

# Package variables
influxdb_apt_key_url: https://repos.influxdata.com/influxdb.key
influxdb_apt_repo: "deb https://repos.influxdata.com/{{ ansible_lsb.id|lower }} {{ ansible_lsb.codename|lower }} stable"

# General variables
influxdb_config_path: /etc/influxdb
influxdb_config_file_name: influxdb.conf
influxdb_config_file_path: "{{ influxdb_config_path }}/{{ influxdb_config_file_name }}"

# Database management
influxdb_databases:
  - database1
  - database2

# User management
influxdb_credentials_admin:
  - username: admin1
    password: CHANGEME
  - username: admin2
    password: CHANGEME

influxdb_credentials_user:
  - username: user1
    password: CHANGEME
    databases:
      - all.database1 # [ALL,READ,WRITE].[database]
      - all.database2
  - username: user2
    password: CHANGEME
    databases:
      - all.database1 # [ALL,READ,WRITE].[database]

## Configuration
global:
  ## Once every 24 hours InfluxDB will report usage data to usage.influxdata.com
  ## The data includes a random ID, os, arch, version, the number of series and other
  ## usage data. No data from user databases is ever transmitted.
  ## Change this option to true to disable reporting.
  reporting_disabled: false

  ## Bind address to use for the RPC service for backup and restore.
  bind_address: ":8088"

influxdb_config:
  ### [meta]
  ###
  ### Controls the parameters for the Raft consensus group that stores metadata
  ### about the InfluxDB cluster.
  ###
  meta:
    ## Where the metadata/raft database is stored
    dir: "/var/lib/influxdb/meta"

    ## Automatically create a default retention policy when creating a database.
    # retention_autocreate: true

    ## If log messages are printed for the meta service
    # logging_enabled: true


  ### [data]
  ###
  ### Controls where the actual shard data for InfluxDB lives and how it is
  ### flushed from the WAL. "dir" may need to be changed to a suitable place
  ### for your system, but the WAL settings are an advanced configuration. The
  ### defaults should work for most systems.
  ###
  data:
    # The directory where the TSM storage engine stores TSM files.
    dir: "/var/lib/influxdb/data"

    # The directory where the TSM storage engine stores WAL files.
    wal_dir: "/var/lib/influxdb/wal"

    ## The amount of time that a write will wait before fsyncing.  A duration
    ## greater than 0 can be used to batch up multiple fsync calls.  This is useful for slower
    ## disks or when WAL write contention is seen.  A value of 0s fsyncs every write to the WAL.
    ## Values in the range of 0-100ms are recommended for non-SSD disks.
    # wal_fsync_delay: "0s"


    ## The type of shard index to use for new shards.  The default is an in-memory index that is
    ## recreated at startup.  A value of "tsi1" will use a disk based index that supports higher
    ## cardinality datasets.
    # index_version: "inmem"

    ## Trace logging provides more verbose output around the tsm engine. Turning
    ## this on can provide more useful output for debugging tsm engine issues.
    # trace_logging_enabled: false

    ## Whether queries should be logged before execution. Very useful for troubleshooting, but will
    ## log any sensitive data contained within a query.
    # query_log_enabled: true

    ## Settings for the TSM engine

    ## CacheMaxMemorySize is the maximum size a shard's cache can
    ## reach before it starts rejecting writes.
    ## Valid size suffixes are k, m, or g (case insensitive, 1024 = 1k).
    ## Values without a size suffix are in bytes.
    # cache_max_memory_size: "1g"

    ## CacheSnapshotMemorySize is the size at which the engine will
    ## snapshot the cache and write it to a TSM file, freeing up memory
    ## Valid size suffixes are k, m, or g (case insensitive, 1024 = 1k).
    ## Values without a size suffix are in bytes.
    # cache_snapshot_memory_size: "25m"

    ## CacheSnapshotWriteColdDuration is the length of time at
    ## which the engine will snapshot the cache and write it to
    ## a new TSM file if the shard hasn't received writes or deletes
    # cache_snapshot_write_cold_duration: "10m"

    ## CompactFullWriteColdDuration is the duration at which the engine
    ## will compact all TSM files in a shard if it hasn't received a
    ## write or delete
    # compact_full_write_cold_duration: "4h"

    ## The maximum number of concurrent full and level compactions that can run at one time.  A
    ## value of 0 results in 50% of runtime.GOMAXPROCS(0) used at runtime.  Any number greater
    ## than 0 limits compactions to that value.  This setting does not apply
    ## to cache snapshotting.
    # max_concurrent_compactions: 0

    ## The threshold, in bytes, when an index write-ahead log file will compact
    ## into an index file. Lower sizes will cause log files to be compacted more
    ## quickly and result in lower heap usage at the expense of write throughput.
    ## Higher sizes will be compacted less frequently, store more series in-memory,
    ## and provide higher write throughput.
    ## Valid size suffixes are k, m, or g (case insensitive, 1024 = 1k).
    ## Values without a size suffix are in bytes.
    # max_index_log_file_size: "1m"

    ## The maximum series allowed per database before writes are dropped.  This limit can prevent
    ## high cardinality issues at the database level.  This limit can be disabled by setting it to
    ## 0.
    # max_series_per_database: 1000000

    ## The maximum number of tag values per tag that are allowed before writes are dropped.  This limit
    ## can prevent high cardinality tag values from being written to a measurement.  This limit can be
    ## disabled by setting it to 0.
    # max_values_per_tag: 100000


  ### [http]
  ###
  ### Controls how the HTTP endpoints are configured. These are the primary
  ### mechanism for getting data into and out of InfluxDB.
  ###
  http:
    ## Determines whether HTTP endpoint is enabled.
    enabled: true

    ## The bind address used by the HTTP service.
    bind_address: ":8086"

    ## Determines whether user authentication is enabled over HTTP/HTTPS.
    auth_enabled: false

    ## The default realm sent back when issuing a basic auth challenge.
    # realm: "InfluxDB"

    ## Determines whether HTTP request logging is enabled.
    # log_enabled: true

    ## Determines whether the HTTP write request logs should be suppressed when the log is enabled.
    # suppress_write_log: false

    ## When HTTP request logging is enabled, this option specifies the path where
    ## log entries should be written. If unspecified, the default is to write to stderr, which
    ## intermingles HTTP logs with internal InfluxDB logging.
    ##
    ## If influxd is unable to access the specified path, it will log an error and fall back to writing
    ## the request log to stderr.
    # access_log_path: ""

    ## Determines whether detailed write logging is enabled.
    # write_tracing: false

    ## Determines whether the pprof endpoint is enabled.  This endpoint is used for
    ## troubleshooting and monitoring.
    # pprof_enabled: true

    ## Determines whether HTTPS is enabled.
    https_enabled: false

    ## The SSL certificate to use when HTTPS is enabled.
    # https_certificate: "/etc/ssl/influxdb.pem"

    ## Use a separate private key location.
    # https_private_key: ""

    ## The JWT auth shared secret to validate requests using JSON web tokens.
    # shared_secret: ""

    ## The default chunk size for result sets that should be chunked.
    # max_row_limit: 0

    ## The maximum number of HTTP connections that may be open at once.  New connections that
    ## would exceed this limit are dropped.  Setting this value to 0 disables the limit.
    # max_connection_limit: 0

    ## Enable http service over unix domain socket
    # unix_socket_enabled: false

    ## The path of the unix domain socket.
    # bind_socket: "/var/run/influxdb.sock"

    ## The maximum size of a client request body, in bytes. Setting this value to 0 disables the limit.
    # max_body_size: 25000000


  ### [coordinator]
  ###
  ### Controls the clustering service configuration.
  ###
  coordinator: {}
    ## The default time a write request will wait until a "timeout" error is returned to the caller.
    # write_timeout: "10s"

    ## The maximum number of concurrent queries allowed to be executing at one time.  If a query is
    ## executed and exceeds this limit, an error is returned to the caller.  This limit can be disabled
    ## by setting it to 0.
    # max_concurrent_queries: 0

    ## The maximum time a query will is allowed to execute before being killed by the system.  This limit
    ## can help prevent run away queries.  Setting the value to 0 disables the limit.
    # query_timeout: "0s"

    ## The time threshold when a query will be logged as a slow query.  This limit can be set to help
    ## discover slow or resource intensive queries.  Setting the value to 0 disables the slow query logging.
    # log_queries_after: "0s"

    ## The maximum number of points a SELECT can process.  A value of 0 will make
    ## the maximum point count unlimited.  This will only be checked every second so queries will not
    ## be aborted immediately when hitting the limit.
    # max_select_point: 0

    ## The maximum number of series a SELECT can run.  A value of 0 will make the maximum series
    ## count unlimited.
    # max_select_series: 0

    ## The maxium number of group by time bucket a SELECT can create.  A value of zero will max the maximum
    ## number of buckets unlimited.
    # max_select_buckets: 0
  

  ### [retention]
  ###
  ### Controls the enforcement of retention policies for evicting old data.
  ###
  retention: {}
    ## Determines whether retention policy enforcement enabled.
    # enabled: true

    ## The interval of time when retention policy enforcement checks run.
    # check_interval: "30m"


  ### [shard-precreation]
  ###
  ### Controls the precreation of shards, so they are available before data arrives.
  ### Only shards that, after creation, will have both a start- and end-time in the
  ### future, will ever be created. Shards are never precreated that would be wholly
  ### or partially in the past.
  shard-precreation: {}
    ## Determines whether shard pre-creation service is enabled.
    # enabled: true

    ## The interval of time when the check to pre-create new shards runs.
    # check_interval: "10m"

    ## The default period ahead of the endtime of a shard group that its successor
    ## group is created.
    # advance_period: "30m"


  ### Controls the system self-monitoring, statistics and diagnostics.
  ###
  ### The internal database for monitoring data is created automatically if
  ### if it does not already exist. The target retention within this database
  ### is called 'monitor' and is also created with a retention period of 7 days
  ### and a replication factor of 1, if it does not exist. In all cases the
  ### this retention policy is configured as the default for the database.
  monitor: {}
    ## Whether to record statistics internally.
    # store_enabled: true

    ## The destination database for recorded statistics
    # store_database: "_internal"

    ## The interval at which to record statistics
    # store_interval: "10s"


  ### [ifql]
  ###
  ### Configures the ifql RPC API.
  ###
  ifql: {}
    ## Determines whether the RPC service is enabled.
    # enabled: true

    ## Determines whether additional logging is enabled.
    # log_enabled: true

    ## The bind address used by the ifql RPC service.
    # bind_address: ":8082"


  ### [logging]
  ###
  ### Controls how the logger emits logs to the output.
  ###
  logging: {}
    ## Determines which log encoder to use for logs. Available options
    ## are auto, logfmt, and json. auto will use a more a more user-friendly
    ## output format if the output terminal is a TTY, but the format is not as
    ## easily machine-readable. When the output is a non-TTY, auto will use
    ## logfmt.
    # format: "auto"

    ## Determines which level of logs will be emitted. The available levels
    ## are error, warn, info, and debug. Logs that are equal to or above the
    ## specified level will be emitted.
    # level: "info"

    # Suppresses the logo output that is printed when the program is started.
    ## The logo is always suppressed if STDOUT is not a TTY.
    # suppress_logo: false
    

  ### [subscriber]
  ###
  ### Controls the subscriptions, which can be used to fork a copy of all data
  ### received by the InfluxDB host.
  ###
  subscriber: {}
    ## Determines whether the subscriber service is enabled.
    # enabled: true

    ## The default timeout for HTTP writes to subscribers.
    # http_timeout: "30s"

    ## Allows insecure HTTPS connections to subscribers.  This is useful when testing with self-
    ## signed certificates.
    # insecure_skip_verify: false

    ## The path to the PEM encoded CA certs file. If the empty string, the default system certs will be used
    # ca_certs: ""

    ## The number of writer goroutines processing the write channel.
    # write_concurrency: 40

    ## The number of in-flight writes buffered in the write channel.
    # write_buffer_size: 1000

  
  ### [continuous_queries]
  ###
  ### Controls how continuous queries are run within InfluxDB.
  ###
  continuous_queries:
    ## Determines whether the continuous query service is enabled.
    enabled: true

    ## Controls whether queries are logged when executed by the CQ service.
    log_enabled: true

    ## Controls whether queries are logged to the self-monitoring data store.
    # query_stats_enabled: false

    ## interval for how often continuous queries will be checked if they need to run
    # run_interval: "1s"
    

  listeners:
    graphite: {}
      ## Determines whether the graphite endpoint is enabled.
      # enabled: false
      # database: "graphite"
      # retention_policy: ""
      # bind_address: ":2003"
      # protocol: "tcp"
      # consistency_level: "one"

      ## These next lines control how batching works. You should have this enabled
      ## otherwise you could get dropped metrics or poor performance. Batching
      ## will buffer points in memory if you have many coming in.

      ## Flush if this many points get buffered
      # batch_size: 5000

      ## number of batches that may be pending in memory
      # batch_pending: 10

      ## Flush at least this often even if we haven't hit buffer limit
      # batch_timeout: "1s"

      ## UDP Read buffer size, 0 means OS default. UDP listener will fail if set above OS max.
      # udp_read_buffer: 0

      ## This string joins multiple matching 'measurement' values providing more control over the final measurement name.
      # separator: "."

      ## Default tags that will be added to all metrics.  These can be overridden at the template level
      ## or by tags extracted from metric
      # tags: ["region=us-east", "zone=1c"]

      ## Each template line requires a template pattern.  It can have an optional
      ## filter before the template and separated by spaces.  It can also have optional extra
      ## tags following the template.  Multiple tags should be separated by commas and no spaces
      ## similar to the line protocol format.  There can be only one default template.
      # templates: [
      #   "*.app env.service.resource.measurement",
      #   # Default template
      #   "server.*",
      # ]


    collectd: {}
      ## enabled: false
      ## bind-address: ":25826"
      ## database: "collectd"
      # retention_policy: ""
      
      ## The collectd service supports either scanning a directory for multiple types
      ## db files, or specifying a single db file.
      # typesdb: "/usr/local/share/collectd"
      # security_level: "none"
      # auth_file: "/etc/collectd/auth_file"

      ## These next lines control how batching works. You should have this enabled
      ## otherwise you could get dropped metrics or poor performance. Batching
      ## will buffer points in memory if you have many coming in.

      ## Flush if this many points get buffered
      # batch_size: 5000

      ## Number of batches that may be pending in memory
      # batch_pending: 10

      ## Flush at least this often even if we haven't hit buffer limit
      # batch_timeout: "10s"

      ## UDP Read buffer size, 0 means OS default. UDP listener will fail if set above OS max.
      # read_buffer: 0

      ## Multi-value plugins can be handled two ways.
      ## "split" will parse and store the multi-value plugin data into separate measurements
      ## "join" will parse and store the multi-value plugin as a single multi-value measurement.
      ## "split" is the default behavior for backward compatability with previous versions of influxdb.
      # parse_multivalue_plugin: "split"

    opentsdb: {}
      # enabled: false
      # bind_address: ":4242"
      # database: "opentsdb"
      # retention_policy: ""
      # consistency_level: "one"
      # tls_enabled: false
      # certificate= "/etc/ssl/influxdb.pem"

      ## Log an error for every malformed point.
      # log_point_errors: true

      ## These next lines control how batching works. You should have this enabled
      ## otherwise you could get dropped metrics or poor performance. Only points
      # metrics received over the telnet protocol undergo batching.

      ## Flush if this many points get buffered
      # batch_size: 1000

      ## Number of batches that may be pending in memory
      # batch_pending: 5

      ## Flush at least this often even if we haven't hit buffer limit
      # batch_timeout: "1s"
    
    
    udp: {}
      # enabled: false
      # bind_address: ":8089"
      # database: "udp"
      # retention_policy: ""

      ## These next lines control how batching works. You should have this enabled
      ## otherwise you could get dropped metrics or poor performance. Batching
      # will buffer points in memory if you have many coming in.

      ## Flush if this many points get buffered
      # batch_size: 5000

      ## Number of batches that may be pending in memory
      # batch_pending: 10

      ## Will flush at least this often even if we haven't hit buffer limit
      # batch_timeout: "1s"

      ## UDP Read buffer size, 0 means OS default. UDP listener will fail if set above OS max.
      # read_buffer: 0
